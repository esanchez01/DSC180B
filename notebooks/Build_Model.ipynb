{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src') \n",
    "\n",
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libraries for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Importing script\n",
    "import etl as etl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disease Risk Classification Model\n",
    "\n",
    "The purpose of this notebook is to explore a variety of models and tune them in order to figure out which is best for disease risk classification. According to the article \"Comparing different supervised machine learning algorithms for disease prediction\" by Shahadat Uddin et al. (https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-019-1004-8), Support Vector Machines, Naive Bayes, and Random Forest are some of the most common machine learning algorithms applied to disease prediction. We will explore these along with other algorithms such as Logistic Regression and K Nearest Neighbors in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get straight into it and simulate a data set of 5,000 individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs1692580</th>\n",
       "      <th>rs2843152</th>\n",
       "      <th>rs36096196</th>\n",
       "      <th>rs10909862</th>\n",
       "      <th>rs2493298</th>\n",
       "      <th>rs17037390</th>\n",
       "      <th>rs10127456</th>\n",
       "      <th>rs35465346</th>\n",
       "      <th>rs113716316</th>\n",
       "      <th>rs12023377</th>\n",
       "      <th>...</th>\n",
       "      <th>rs111245230</th>\n",
       "      <th>rs10981012</th>\n",
       "      <th>rs41311933</th>\n",
       "      <th>rs10818576</th>\n",
       "      <th>rs885150</th>\n",
       "      <th>rs579459</th>\n",
       "      <th>rs495828</th>\n",
       "      <th>rs16999497</th>\n",
       "      <th>PRS</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226.012239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.663000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>86.497028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91.766276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137.421000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 778 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rs1692580  rs2843152  rs36096196  rs10909862  rs2493298  rs17037390  \\\n",
       "0          0          1           0           0          0           1   \n",
       "1          0          1           0           1          0           0   \n",
       "2          0          1           0           1          0           0   \n",
       "3          0          1           0           1          0           0   \n",
       "4          1          1           0           1          1           0   \n",
       "\n",
       "   rs10127456  rs35465346  rs113716316  rs12023377  ...  rs111245230  \\\n",
       "0           0           0            0           0  ...            0   \n",
       "1           0           0            0           0  ...            0   \n",
       "2           0           0            0           0  ...            0   \n",
       "3           0           0            0           0  ...            0   \n",
       "4           0           0            0           0  ...            0   \n",
       "\n",
       "   rs10981012  rs41311933  rs10818576  rs885150  rs579459  rs495828  \\\n",
       "0           0           0           1         0         0         0   \n",
       "1           0           0           0         0         0         0   \n",
       "2           0           0           1         1         1         0   \n",
       "3           1           0           0         0         0         0   \n",
       "4           0           0           0         0         0         0   \n",
       "\n",
       "   rs16999497         PRS  Class  \n",
       "0           0  226.012239      1  \n",
       "1           0   86.663000      0  \n",
       "2           1   86.497028      0  \n",
       "3           0   91.766276      0  \n",
       "4           0  137.421000      0  \n",
       "\n",
       "[5 rows x 778 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulated_gwas_fp = '../testdata/gwas/gwas_simulate.tsv' \n",
    "maf_fp = '../references/snp_mafs.txt'\n",
    "simulated_data = etl.simulate_data(simulated_gwas_fp, maf_fp, 5000)\n",
    "simulated_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not be using the simulated data above for building the model. Given that the class label (disease risk category) was assigned to an individual depending on the weighted sum of all and only the SNPs in this data set, it would be too easy for a machine learning model to figure this out. Essentially, the above data set is a simulated 'ground truth'. In machine learning problems you typically don't work with all the variables that determine the label so something needs to be done about this.\n",
    "\n",
    "As a solution, we will be making classifications based on a subset of SNPs in the above data set. To do this, we will be using a separate GWAS to inform us of SNPs that are most important in predicting disease. Only those SNPs that are in the above data set and the new GWAS will be used. The model will then be trained on this subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the other GWAS data and filter the above data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gwas_fp = '../testdata/gwas/gwas_model.tsv' \n",
    "model_data = pd.read_csv(model_gwas_fp, sep='\\t')\n",
    "subset = set(simulated_data.columns).intersection(model_data['SNPS'].unique())\n",
    "new_columns = list(subset)+['Class']\n",
    "\n",
    "data = simulated_data[new_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a training and test set on the above data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train different models on these sets and assess their results.\n",
    "\n",
    "**Note:**\n",
    "\n",
    ">It is important to note that accuracy is not the only metric that is important here to assess the performance of the models. Since we are working with predicting the disease risk of individuals, **Type I** and **Type II** errors are also very important. It is potentially dangerous to classify an individual as low risk when they are actually high risk (Type II, False Negative). Additionally, classifying an individual as high risk when they are actually low risk could cause the individual some unecessary stress within themselves and their families (Type I, False Positive). Therefore, it is important to control for such errors in our model. To do so, we will prioritize the maximization of **Recall** (TP/TP+FN) since it is an indicator of the dangerous False Negatives in our model but at the same time attempt to maximize **Precision** (TP/TP+FP) since it is an indicator of False Positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Logistic Regression model is 85.28%\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(X_train, y_train)\n",
    "\n",
    "accuracy_lg = lg.score(X_test, y_test)*100\n",
    "print('The accuracy for the Logistic Regression model is {}%'.format(accuracy_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's attempt to improve the model using grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the refined Logistic Regression model is 90.56%\n"
     ]
    }
   ],
   "source": [
    "lg_parameters = {'tol':[.1, .001, .0001], 'C':[10, 1, .1]}\n",
    "lg = LogisticRegression()\n",
    "clf1 = GridSearchCV(lg, lg_parameters)\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "preds_lg = clf1.predict(X_test)\n",
    "accuracy_lr = np.mean(y_test == preds_lg)*100\n",
    "\n",
    "\n",
    "print('The accuracy for the refined Logistic Regression model is {}%'.format(accuracy_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Low Risk       0.98      1.00      0.99       693\n",
      " Medium Risk       0.88      0.79      0.83       367\n",
      "   High Risk       0.69      0.79      0.74       190\n",
      "\n",
      "    accuracy                           0.91      1250\n",
      "   macro avg       0.85      0.86      0.85      1250\n",
      "weighted avg       0.91      0.91      0.91      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Low Risk', 'Medium Risk', 'High Risk']\n",
    "print(classification_report(y_test, preds_lg, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the K Nearest Neighbors model is 0.7712%\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "accuracy_knn = knn.score(X_test, y_test)\n",
    "print('The accuracy for the K Nearest Neighbors model is {}%'.format(accuracy_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's attempt to improve the model using grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the refined K Nearest Neighbors model is 79.67999999999999%\n"
     ]
    }
   ],
   "source": [
    "knn_parameters = {'n_neighbors':[10, 5, 3, 1], 'p':[2, 1]}\n",
    "knn = KNeighborsClassifier()\n",
    "clf2 = GridSearchCV(knn, knn_parameters)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "preds_knn = clf2.predict(X_test)\n",
    "accuracy_knn = np.mean(y_test == preds_knn)*100\n",
    "\n",
    "print('The accuracy for the refined K Nearest Neighbors model is {}%'.format(accuracy_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Low Risk       0.76      1.00      0.86       693\n",
      " Medium Risk       1.00      0.31      0.47       367\n",
      "   High Risk       0.84      1.00      0.91       190\n",
      "\n",
      "    accuracy                           0.80      1250\n",
      "   macro avg       0.87      0.77      0.75      1250\n",
      "weighted avg       0.84      0.80      0.76      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_knn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Support Vector Machine model is 99.92%\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "accuracy_svc = svc.score(X_test, y_test)*100\n",
    "print('The accuracy for the Support Vector Machine model is {}%'.format(accuracy_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the refined Support Vector Machine model is 0.9992\n"
     ]
    }
   ],
   "source": [
    "svc_parameters = {'tol': [.1, .001, .0001], 'C':[10, 1, .1]}\n",
    "svc = SVC()\n",
    "clf3 = GridSearchCV(svc, svc_parameters)\n",
    "\n",
    "clf3.fit(X_train, y_train)\n",
    "preds_svc = clf3.predict(X_test)\n",
    "accuracy_svc = np.mean(y_test == preds_svc)\n",
    "\n",
    "print('The accuracy for the refined Support Vector Machine model is {}'.format(accuracy_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Low Risk       1.00      1.00      1.00       693\n",
      " Medium Risk       1.00      1.00      1.00       367\n",
      "   High Risk       1.00      1.00      1.00       190\n",
      "\n",
      "    accuracy                           1.00      1250\n",
      "   macro avg       1.00      1.00      1.00      1250\n",
      "weighted avg       1.00      1.00      1.00      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_svc, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Naive Bayes is 95.76%\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "accuracy_gnb = gnb.score(X_test, y_test)*100\n",
    "print('The accuracy for the Naive Bayes is {}%'.format(accuracy_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the refined Naive Bayes model is 0.9696\n"
     ]
    }
   ],
   "source": [
    "gnb_parameters = {'var_smoothing':[1e-3, 1e-6, 1e-9]}\n",
    "gnb = GaussianNB()\n",
    "clf4 = GridSearchCV(gnb, gnb_parameters)\n",
    "\n",
    "clf4.fit(X_train, y_train)\n",
    "preds_gnb = clf4.predict(X_test)\n",
    "accuracy_gnb = np.mean(y_test == preds_gnb)\n",
    "\n",
    "print('The accuracy for the refined Naive Bayes model is {}'.format(accuracy_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Low Risk       1.00      0.96      0.98       693\n",
      " Medium Risk       0.91      0.99      0.95       367\n",
      "   High Risk       1.00      0.95      0.98       190\n",
      "\n",
      "    accuracy                           0.97      1250\n",
      "   macro avg       0.97      0.97      0.97      1250\n",
      "weighted avg       0.97      0.97      0.97      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_gnb, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Random Forest is 81.67999999999999%\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "accuracy_rf = rf.score(X_test, y_test)*100\n",
    "print('The accuracy for the Random Forest is {}%'.format(accuracy_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the refined Random Forest model is 0.9264\n"
     ]
    }
   ],
   "source": [
    "rf_parameters = {'n_estimators':[100, 50, 10]}\n",
    "rf = RandomForestClassifier()\n",
    "clf5 = GridSearchCV(rf, rf_parameters)\n",
    "\n",
    "clf5.fit(X_train, y_train)\n",
    "preds_rf = clf5.predict(X_test)\n",
    "accuracy_rf = np.mean(y_test == preds_rf)\n",
    "\n",
    "print('The accuracy for the refined Random Forest model is {}'.format(accuracy_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Low Risk       0.89      1.00      0.94       693\n",
      " Medium Risk       0.99      0.75      0.86       367\n",
      "   High Risk       1.00      0.99      0.99       190\n",
      "\n",
      "    accuracy                           0.93      1250\n",
      "   macro avg       0.96      0.91      0.93      1250\n",
      "weighted avg       0.93      0.93      0.92      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_rf, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
